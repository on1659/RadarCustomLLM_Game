#!/bin/bash
# DPO í•™ìŠµ í™˜ê²½ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸

set -e

echo "ğŸš€ DPO í•™ìŠµ í™˜ê²½ ì„¤ì¹˜"
echo ""

# Python ë²„ì „ í™•ì¸
echo "ğŸ“Œ Python ë²„ì „ í™•ì¸..."
python3 --version || {
    echo "âŒ Python3ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    exit 1
}

# Virtual environment ìƒì„±
VENV_DIR="$HOME/Work/LLM/dpo/venv"

if [ ! -d "$VENV_DIR" ]; then
    echo ""
    echo "ğŸ”§ Virtual environment ìƒì„± ì¤‘..."
    python3 -m venv "$VENV_DIR"
    echo "âœ… venv ìƒì„± ì™„ë£Œ: $VENV_DIR"
else
    echo ""
    echo "âœ… venv ì´ë¯¸ ì¡´ì¬: $VENV_DIR"
fi

# venv í™œì„±í™”
echo ""
echo "ğŸ”Œ venv í™œì„±í™”..."
source "$VENV_DIR/bin/activate"

# pip ì—…ê·¸ë ˆì´ë“œ
echo ""
echo "ğŸ“¦ pip ì—…ê·¸ë ˆì´ë“œ..."
pip install --upgrade pip

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
echo ""
echo "ğŸ“š í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘..."
pip install \
    torch \
    transformers \
    datasets \
    accelerate \
    peft \
    bitsandbytes \
    trl

echo ""
echo "âš ï¸  unsloth ì œì™¸ë¨ (xformers ë¹Œë“œ ì´ìŠˆ)"
echo "   â†’ trl DPOTrainerë¡œ í•™ìŠµ (ë™ì¼ ê¸°ëŠ¥)"

echo ""
echo "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!"

# llama.cpp í™•ì¸
echo ""
echo "ğŸ”§ llama.cpp í™•ì¸..."
if [ ! -d "$HOME/Work/LLM/llama.cpp" ]; then
    echo "âš ï¸  llama.cppê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    echo ""
    read -p "ì§€ê¸ˆ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " install_llama
    
    if [ "$install_llama" = "y" ] || [ "$install_llama" = "Y" ]; then
        cd ~/Work/LLM
        git clone https://github.com/ggerganov/llama.cpp
        cd llama.cpp
        make
        pip3 install -r requirements.txt
        echo "âœ… llama.cpp ì„¤ì¹˜ ì™„ë£Œ!"
    else
        echo "â­ï¸  ê±´ë„ˆëœ€. ë‚˜ì¤‘ì— ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:"
        echo "   cd ~/Work/LLM"
        echo "   git clone https://github.com/ggerganov/llama.cpp"
        echo "   cd llama.cpp && make"
    fi
else
    echo "âœ… llama.cpp ì´ë¯¸ ì„¤ì¹˜ë¨"
fi

# GPU/MPS í™•ì¸
echo ""
echo "ğŸ® GPU/MPS í™•ì¸..."
python3 -c "
import torch
if torch.cuda.is_available():
    print('âœ… CUDA ì‚¬ìš© ê°€ëŠ¥:', torch.cuda.get_device_name(0))
elif torch.backends.mps.is_available():
    print('âœ… MPS (Apple Silicon) ì‚¬ìš© ê°€ëŠ¥')
else:
    print('âš ï¸  GPU/MPS ì—†ìŒ - CPU í•™ìŠµ (ëŠë¦¼)')
"

echo ""
echo "ğŸ‰ ì„¤ì¹˜ ì™„ë£Œ!"
echo ""
echo "ë‹¤ìŒ ë‹¨ê³„:"
echo "  1. python3 dpo/collect-data.py  # ë°ì´í„° ìˆ˜ì§‘"
echo "  2. python3 dpo/manual-fix.py    # ìˆ˜ë™ ë‹µë³€ ì‘ì„±"
echo "  3. python3 dpo/train.py         # DPO í•™ìŠµ"

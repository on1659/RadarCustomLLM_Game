#!/usr/bin/env python3
"""
ë‚˜ë¬´ìœ„í‚¤ í¬ë¡¤ëŸ¬ â€” ê²Œì„ ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ì €ì¥
ì‚¬ìš©ë²•: python3 namu_crawler.py
"""

import requests
import re
import json
import os
import time
from pathlib import Path
from urllib.parse import quote

OUTPUT_DIR = Path(__file__).parent / "data"
OUTPUT_DIR.mkdir(exist_ok=True)

# í¬ë¡¤ë§í•  ë¬¸ì„œ ëª©ë¡
PAGES = {
    "palworld": [
        "íŒ°ì›”ë“œ",
        "íŒ°ì›”ë“œ/íŒ°",
        "íŒ°ì›”ë“œ/ë„ê°",
        "íŒ°ì›”ë“œ/ë³´ìŠ¤",
        "íŒ°ì›”ë“œ/ê¸°ìˆ ",
        "íŒ°ì›”ë“œ/ê±°ì ",
        "íŒ°ì›”ë“œ/ì•„ì´í…œ",
        "íŒ°ì›”ë“œ/ë¬´ê¸°",
        "íŒ°ì›”ë“œ/ë°©ì–´êµ¬",
        "íŒ°ì›”ë“œ/ê±´ì¶•",
        "íŒ°ì›”ë“œ/íƒˆê²ƒ",
        "íŒ°ì›”ë“œ/ë²ˆì‹",
        "íŒ°ì›”ë“œ/íŒ",
    ],
    "overwatch": [
        "ì˜¤ë²„ì›Œì¹˜ 2",
        "ì˜¤ë²„ì›Œì¹˜/ì˜ì›…",
        "ì˜¤ë²„ì›Œì¹˜/ì˜ì›…/ëŒê²©",
        "ì˜¤ë²„ì›Œì¹˜/ì˜ì›…/í”¼í•´",
        "ì˜¤ë²„ì›Œì¹˜/ì˜ì›…/ì§€ì›",
        "ì˜¤ë²„ì›Œì¹˜/ê²Œì„ ëª¨ë“œ",
        "ì˜¤ë²„ì›Œì¹˜/ì „ì¥",
        "ì˜¤ë²„ì›Œì¹˜/ì•„ì´í…œ",
        "ì˜¤ë²„ì›Œì¹˜/ê²½ìŸì „",
        # ê°œë³„ ì˜ì›…
        "íŠ¸ë ˆì´ì„œ(ì˜¤ë²„ì›Œì¹˜)",
        "ê²ì§€(ì˜¤ë²„ì›Œì¹˜)",
        "ë¦¬í¼(ì˜¤ë²„ì›Œì¹˜)",
        "ì†”ì €: 76",
        "íŒŒë¼(ì˜¤ë²„ì›Œì¹˜)",
        "ì•„ë‚˜(ì˜¤ë²„ì›Œì¹˜)",
        "ë£¨ì‹œìš°(ì˜¤ë²„ì›Œì¹˜)",
        "ë¨¸ì‹œ(ì˜¤ë²„ì›Œì¹˜)",
        "ë¼ì¸í•˜ë¥´íŠ¸(ì˜¤ë²„ì›Œì¹˜)",
        "ë””ë°”(ì˜¤ë²„ì›Œì¹˜)",
        "ìœ„ë„ìš°ë©”ì´ì»¤(ì˜¤ë²„ì›Œì¹˜)",
        "í•œì¡°(ì˜¤ë²„ì›Œì¹˜)",
        "ì •í¬ë«(ì˜¤ë²„ì›Œì¹˜)",
        "ë©”ì´(ì˜¤ë²„ì›Œì¹˜)",
        "ë°”ìŠ¤í‹°ì˜¨(ì˜¤ë²„ì›Œì¹˜)",
    ],
    "minecraft": [
        "ë§ˆì¸í¬ë˜í”„íŠ¸",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ì•„ì´í…œ",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ë¸”ë¡",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ëª¹",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ë°”ì´ì˜´",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ì¸ì±ˆíŠ¸",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ì–‘ì¡°",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ë ˆë“œìŠ¤í†¤",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ì—”ë” ë“œë˜ê³¤",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ìœ„ë”",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ë„¤ë”",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ì—”ë“œ",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ë§ˆì„",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ë†ì‚¬",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/ì¡°í•©ë²•",
        "ë§ˆì¸í¬ë˜í”„íŠ¸/íŒ",
    ],
}

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}


def clean_namu_text(raw_html: str) -> str:
    """ë‚˜ë¬´ìœ„í‚¤ HTMLì—ì„œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    # HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<script[^>]*>.*?</script>', '', raw_html, flags=re.DOTALL)
    text = re.sub(r'<style[^>]*>.*?</style>', '', raw_html, flags=re.DOTALL)
    text = re.sub(r'<[^>]+>', ' ', text)
    # ë‚˜ë¬´ìœ„í‚¤ ë¬¸ë²• ì •ë¦¬
    text = re.sub(r'\[\[([^\]|]+)\|([^\]]+)\]\]', r'\2', text)  # [[ë§í¬|í…ìŠ¤íŠ¸]] â†’ í…ìŠ¤íŠ¸
    text = re.sub(r'\[\[([^\]]+)\]\]', r'\1', text)  # [[ë§í¬]] â†’ ë§í¬
    text = re.sub(r'\{\{[^}]*\}\}', '', text)  # {{ë§¤í¬ë¡œ}} ì œê±°
    text = re.sub(r'&#\d+;', ' ', text)  # HTML ì—”í‹°í‹°
    text = re.sub(r'&[a-z]+;', ' ', text)
    # ì—¬ëŸ¬ ê³µë°±/ì¤„ë°”ê¿ˆ ì •ë¦¬
    text = re.sub(r'[ \t]+', ' ', text)
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()


def fetch_namu_page(title: str) -> str | None:
    """ë‚˜ë¬´ìœ„í‚¤ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° (API ì‚¬ìš©)"""
    encoded = quote(title, safe='')
    
    # ë‚˜ë¬´ìœ„í‚¤ raw ë¬¸ì„œ ì‹œë„
    url = f"https://namu.wiki/w/{encoded}"
    try:
        resp = requests.get(url, headers=HEADERS, timeout=15)
        if resp.status_code == 200:
            return clean_namu_text(resp.text)
        else:
            print(f"  âš ï¸ HTTP {resp.status_code}: {title}")
            return None
    except Exception as e:
        print(f"  âŒ ì—ëŸ¬: {title} â€” {e}")
        return None


def crawl_game(game: str, pages: list[str]):
    """ê²Œì„ë³„ ë¬¸ì„œ í¬ë¡¤ë§"""
    game_dir = OUTPUT_DIR / game
    game_dir.mkdir(exist_ok=True)
    
    results = []
    
    print(f"\n{'='*50}")
    print(f"ğŸ® {game.upper()} í¬ë¡¤ë§ ì‹œì‘ ({len(pages)}ê°œ ë¬¸ì„œ)")
    print(f"{'='*50}")
    
    for i, title in enumerate(pages, 1):
        print(f"  [{i}/{len(pages)}] {title}...", end=" ", flush=True)
        
        text = fetch_namu_page(title)
        if text and len(text) > 100:  # ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
            # ê°œë³„ íŒŒì¼ ì €ì¥
            safe_name = re.sub(r'[/\\:*?"<>|]', '_', title)
            filepath = game_dir / f"{safe_name}.txt"
            filepath.write_text(text, encoding='utf-8')
            
            results.append({
                "title": title,
                "file": str(filepath),
                "length": len(text),
            })
            print(f"âœ… ({len(text):,}ì)")
        else:
            print(f"â­ï¸ ìŠ¤í‚µ (ë‚´ìš© ì—†ìŒ)")
        
        time.sleep(2)  # 2ì´ˆ ëŒ€ê¸° (rate limit)
    
    # ê²Œì„ë³„ ë©”íƒ€ë°ì´í„° ì €ì¥
    meta_path = game_dir / "_meta.json"
    with open(meta_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    total_chars = sum(r["length"] for r in results)
    print(f"\nğŸ“Š {game}: {len(results)}ê°œ ë¬¸ì„œ, ì´ {total_chars:,}ì ì €ì¥")
    
    return results


def main():
    print("ğŸ•·ï¸ ë‚˜ë¬´ìœ„í‚¤ ê²Œì„ í¬ë¡¤ëŸ¬ ì‹œì‘")
    print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {OUTPUT_DIR}")
    
    all_results = {}
    for game, pages in PAGES.items():
        all_results[game] = crawl_game(game, pages)
    
    # ì „ì²´ ìš”ì•½
    print(f"\n{'='*50}")
    print("ğŸ“‹ í¬ë¡¤ë§ ì™„ë£Œ ìš”ì•½")
    print(f"{'='*50}")
    
    total_docs = 0
    total_chars = 0
    for game, results in all_results.items():
        docs = len(results)
        chars = sum(r["length"] for r in results)
        total_docs += docs
        total_chars += chars
        print(f"  ğŸ® {game}: {docs}ê°œ ë¬¸ì„œ, {chars:,}ì")
    
    print(f"\n  ì´í•©: {total_docs}ê°œ ë¬¸ì„œ, {total_chars:,}ì")
    print(f"  ì €ì¥ ìœ„ì¹˜: {OUTPUT_DIR}")
    print("\nâœ… ì™„ë£Œ! RAGì— ì´ ë°ì´í„°ë¥¼ ë„£ìœ¼ë©´ ë©ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()

"""ë‚˜ë¬´ìœ„í‚¤ RAG ì±—ë´‡ â€” ë¡œì»¬ llama-server ì—°ë™"""
import os
import requests
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

DB_DIR = os.path.join(os.path.dirname(__file__), "faiss_db")
LLAMA_URL = "http://localhost:8090/v1/chat/completions"

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ê²Œì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì°¸ê³  ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
ì°¸ê³  ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ "í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.

[ì°¸ê³  ìë£Œ]
{context}"""


def load_db():
    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")
    return FAISS.load_local(DB_DIR, embeddings, allow_dangerous_deserialization=True)


def search(db, query, k=5):
    results = db.similarity_search(query, k=k)
    context = ""
    for doc in results:
        game = doc.metadata.get("game", "?")
        title = doc.metadata.get("title", "?")
        context += f"\n[{game} - {title}]\n{doc.page_content}\n"
    return context, results


def ask_llm(query, context):
    system = SYSTEM_PROMPT.format(context=context)
    payload = {
        "messages": [
            {"role": "system", "content": system},
            {"role": "user", "content": query},
        ],
        "max_tokens": 1024,
        "temperature": 0.3,
        "repeat_penalty": 1.3,
    }
    try:
        resp = requests.post(LLAMA_URL, json=payload, timeout=60)
        resp.raise_for_status()
        return resp.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"âŒ LLM ì—°ê²° ì‹¤íŒ¨: {e}"


def main():
    print("ğŸ® ê²Œì„ ë‚˜ë¬´ìœ„í‚¤ RAG ì±—ë´‡")
    print("   íŒ°ì›”ë“œ / ì˜¤ë²„ì›Œì¹˜ / ë§ˆì¸í¬ë˜í”„íŠ¸")
    print("   ì¢…ë£Œ: quit ë˜ëŠ” Ctrl+C\n")

    db = load_db()
    print("âœ… ë²¡í„°DB ë¡œë“œ ì™„ë£Œ!\n")

    while True:
        try:
            query = input("ğŸ¯ ì§ˆë¬¸: ").strip()
        except (KeyboardInterrupt, EOFError):
            print("\nğŸ‘‹ ì¢…ë£Œ!")
            break

        if not query or query.lower() in ("quit", "exit", "q"):
            print("ğŸ‘‹ ì¢…ë£Œ!")
            break

        # ê²€ìƒ‰
        context, docs = search(db, query)
        print(f"  ğŸ“š {len(docs)}ê°œ ê´€ë ¨ ë¬¸ì„œ ì°¾ìŒ")

        # LLM ë‹µë³€
        answer = ask_llm(query, context)
        print(f"\nğŸ’¬ {answer}\n")
        print("-" * 50)


if __name__ == "__main__":
    main()
